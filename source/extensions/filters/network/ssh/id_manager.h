#pragma once

#include "fmt/args.h"
#include "source/common/id_alloc.h"
#include "source/extensions/filters/network/ssh/common.h"
#include "source/extensions/filters/network/ssh/wire/messages.h"
#include "source/extensions/filters/network/ssh/common.h"

#pragma clang unsafe_buffer_usage begin
#include "envoy/event/dispatcher.h"
#include "source/common/common/callback_impl.h"
#pragma clang unsafe_buffer_usage end

namespace Envoy::Extensions::NetworkFilters::GenericProxy::Codec {

constexpr uint32_t DefaultMaxConcurrentChannels = 32768;

enum Peer {
  Downstream = 0,
  Upstream = 1,
};

enum class ChannelIDState {
  Unbound = 0,
  Bound = 1,
  Released = 2,
  ClosedReleased = 3,
};

struct PeerLocalID {
  uint32_t channel_id;
  Peer local_peer;
};

struct InternalChannelInfo {
  std::array<uint32_t, 2> peer_ids;
  std::array<ChannelIDState, 2> peer_states;

  Peer owner{};
};

constexpr auto format_as(const InternalChannelInfo& info) {
  fmt::dynamic_format_arg_store<fmt::format_context> args;
  for (auto peer : {Peer::Upstream, Peer::Downstream}) {
    args.push_back(info.owner == peer ? "*" : "");
    args.push_back(info.peer_states[peer]);
    if (info.peer_states[peer] != ChannelIDState::Unbound) {
      args.push_back(":");
      args.push_back(info.peer_ids[peer]);
    } else {
      args.push_back("");
      args.push_back("");
    }
  }
  return fmt::vformat("U{}:{}{}{}|D{}:{}{}{}", args);
}

// Manages channel ID mappings.
// Channel IDs for proxied SSH connections are managed as follows:
//
// Both the downstream and upstream can open channels on the connection via ChannelOpenMsg. When
// doing so, whichever side opens the channel provides their own ID for that channel. Then, if the
// channel is opened successfully, the other side responds with *their* own channel ID for that
// channel. All channel messages after ChannelOpen, including the open response, have a field
// (in our messages, named 'recipient_channel') which contains the peer's channel ID for which the
// message applies. This ID is the one given by the peer itself.
//
// Thus, normally, any given channel can be identified by two separate IDs:
// 1. The ID provided by the downstream, which the upstream uses to send messages to the downstream
// 2. The ID provided by the upstream, which the downstream uses to send messages to the upstream
//
// In our case however, we maintain a third internal channel ID. Because we do not have control over
// the IDs generated by either party, forwarding channel IDs directly could lead to ID conflicts
// in some cases. For example, if we need to open a channel to the upstream ourselves, the
// downstream does not know this, and if it then tries to open another channel, it could generate
// the ID of a channel we have already created (the IDs are usually generated monotonically).
//
// To solve this, we do the following (note this is independent of which peer is the downstream or
// upstream, so we call them Alice and Bob):
// 1. A ChannelOpenMsg received from Alice has its 'sender_channel' field swapped with a
//    newly-generated internal channel ID before it is sent to Bob. The mapping between Alice's
//    sender_channel and ours is stored here, as the original sender_channel is the ID which must
//    be used when messages are ultimately sent back to Alice, regardless of source.
// 2. A ChannelOpenConfirmationMsg sent by Bob to Alice in response contains both sender_channel
//    and recipient_channel fields. The sender_channel here is Bob's new channel ID, and the
//    recipient_channel is *our* internal ID. Before forwarding this message to Alice, we will
//    make the following changes:
//    - The sender_channel (Bob's ID) is stored, and replaced with the recipient_channel (our ID).
//    - The recipient_channel is replaced with Alice's ID, obtained by lookup from our internal ID.
// 3. For any subsequent channel messages (see concept ChannelMsg), it can be assumed that the
//    recipient_channel refers to our internal ID. If the message is to be sent to Bob, the
//    recipient_channel is replaced with Bob's ID, which was tracked in (2). If the message is to
//    be sent to Alice, the recipient_channel is replaced with Alice's ID, which was tracked in (1).
//
// Internal channels keep track of the upstream and downstream channel IDs and whether or not they
// have been "bound" to the internal ID. The ID is only fully released for re-use once a matching
// call to releaseChannelID() has been made for each peer that has called bindChannelID() for the ID.
// Because individual Channel instances only handle messages read from their local peer, not
// messages sent from the remote peer, this allows a Channel to be destroyed when it is done
// handling any reads on the channel (i.e. after reading a ChannelClose message), and still allow
// the opposite peer to respond with their own ChannelClose message to the correct channel ID.
// At the protocol level, the channel is not "closed" until both sides have sent and received a
// ChannelClose message. Only when this happens is the ID released for re-use.
//
class ChannelIDManager : NonCopyable,
                         public StreamInfo::FilterState::Object,
                         public Logger::Loggable<Logger::Id::filter> {
public:
  ChannelIDManager(uint32_t start_id = 0, uint32_t id_limit = DefaultMaxConcurrentChannels)
      : id_alloc_(start_id, start_id + id_limit) {}

  absl::StatusOr<uint32_t> allocateNewChannel(Peer owner);

  absl::Status bindChannelID(uint32_t internal_id, PeerLocalID peer_local_id);
  void releaseChannelID(uint32_t internal_id, Peer local_peer, bool set_closed_internally = false);

  std::optional<Peer> owner(uint32_t internal_id) {
    if (!internal_channels_.contains(internal_id)) {
      return std::nullopt;
    }
    return internal_channels_[internal_id].owner;
  }

  template <wire::ChannelMsg M>
  absl::StatusOr<bool> processOutgoingChannelMsg(M& msg, Peer dest) {
    return processOutgoingChannelMsgImpl(msg.recipient_channel, msg.msg_type(), dest);
  }

  size_t numActiveChannels() const { return internal_channels_.size(); }
  uint32_t nextInternalIdForTest() const { return id_alloc_.peekNext(); }

  [[nodiscard]]
  Envoy::Common::CallbackHandlePtr startDrain(Envoy::Event::Dispatcher& dispatcher, std::function<void()> complete_cb) {
    if (draining_) {
      return nullptr;
    }
    draining_ = true;
    auto handle = drain_cb_->add(dispatcher, std::move(complete_cb));
    if (internal_channels_.empty()) {
      // already drained
      drain_cb_->runCallbacks();
    }
    return handle;
  }

private:
  absl::StatusOr<bool> processOutgoingChannelMsgImpl(wire::field<uint32_t>& recipient_channel,
                                                     wire::SshMessageType msg_type,
                                                     Peer dest);
  absl::flat_hash_map<uint32_t, InternalChannelInfo> internal_channels_;
  IDAllocator<uint32_t> id_alloc_;
  bool draining_{false};
  std::shared_ptr<Envoy::Common::ThreadSafeCallbackManager> drain_cb_ =
    Common::ThreadSafeCallbackManager::create();
};

} // namespace Envoy::Extensions::NetworkFilters::GenericProxy::Codec

DECL_BASIC_ENUM_FORMATTER(Envoy::Extensions::NetworkFilters::GenericProxy::Codec::Peer);
DECL_BASIC_ENUM_FORMATTER(Envoy::Extensions::NetworkFilters::GenericProxy::Codec::ChannelIDState);